{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2633cd39",
   "metadata": {},
   "source": [
    "### Download LEGO-VLM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e682ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface_hub\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_folder = snapshot_download(\n",
    "    repo_id=\"PPPPPeter/arta\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"./\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5daa184",
   "metadata": {},
   "source": [
    "### Grounding benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rouge-score sacrebleu nltk pandas\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "from sacrebleu import sentence_bleu\n",
    "\n",
    "# Download tokenizer models\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Load all examples from the JSONL file\n",
    "examples = []\n",
    "with open('eval_1/eval_grounding.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        examples.append(json.loads(line))\n",
    "\n",
    "# Function to compute token-overlap F1 (F1-Theme)\n",
    "def compute_f1_theme(gold, pred):\n",
    "    gt_tokens = nltk.word_tokenize(gold.lower())\n",
    "    pr_tokens = nltk.word_tokenize(pred.lower())\n",
    "    common = set(gt_tokens) & set(pr_tokens)\n",
    "    if not common:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pr_tokens)\n",
    "    recall = len(common) / len(gt_tokens)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "\n",
    "# Compute metrics for each example\n",
    "rows = []\n",
    "for ex in examples:\n",
    "    gt = ex[\"ground_truth\"]\n",
    "    pr = ex[\"prediction\"]\n",
    "    f1 = compute_f1_theme(gt, pr)\n",
    "    rouge = scorer.score(gt, pr)\n",
    "    bleu = sentence_bleu(pr, [gt]).score\n",
    "    \n",
    "    rows.append({\n",
    "        \"F1-Theme\": f1,\n",
    "        \"ROUGE-1\": rouge['rouge1'].fmeasure,\n",
    "        \"ROUGE-2\": rouge['rouge2'].fmeasure,\n",
    "        \"ROUGE-L\": rouge['rougeL'].fmeasure,\n",
    "        \"BLEU\": bleu\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_metrics = df.mean()\n",
    "\n",
    "# Display results\n",
    "print(\"\\nAverage Metrics:\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    if metric == \"BLEU\":\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f8e36",
   "metadata": {},
   "source": [
    "### State benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29923b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# Load JSONL file\n",
    "with open('eval_1/eval_state.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "\n",
    "for example in data:\n",
    "    # Extract ground truth\n",
    "    gt = example.get(\"ground_truth\", \"\").strip().lower()\n",
    "    pred = example.get(\"prediction\", \"\").strip().lower()\n",
    "\n",
    "    # Ensure both are either \"yes\" or \"no\"\n",
    "    if \"yes\" in gt:\n",
    "        gt_binary = \"yes\"\n",
    "    elif \"no\" in gt:\n",
    "        gt_binary = \"no\"\n",
    "    else:\n",
    "        continue  # skip malformed GT\n",
    "\n",
    "    if \"yes\" in pred:\n",
    "        pred_binary = \"yes\"\n",
    "    elif \"no\" in pred:\n",
    "        pred_binary = \"no\"\n",
    "    else:\n",
    "        pred_binary = \"no\"  # default to no if invalid\n",
    "\n",
    "    ground_truths.append(gt_binary)\n",
    "    predictions.append(pred_binary)\n",
    "\n",
    "# Convert to binary labels\n",
    "y_true = [1 if x == \"yes\" else 0 for x in ground_truths]\n",
    "y_pred = [1 if x == \"yes\" else 0 for x in predictions]\n",
    "\n",
    "# Compute metrics\n",
    "f1 = f1_score(y_true, y_pred, average='binary', pos_label=1)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# False Positive Rate: FP / (FP + TN)\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "# Print results\n",
    "print(f\"Total examples processed: {len(ground_truths)}\")\n",
    "print(f\"F1-State: {f1:.4f}\")\n",
    "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09f0d4",
   "metadata": {},
   "source": [
    "### Object detection benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f713aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "#Functions from process_vision_info\n",
    "IMAGE_FACTOR = 28\n",
    "MIN_PIXELS = 4 * 28 * 28\n",
    "MAX_PIXELS = 2600 * 28 * 28\n",
    "MAX_RATIO = 200\n",
    "\n",
    "def round_by_factor(number: int, factor: int) -> int:\n",
    "    return round(number / factor) * factor\n",
    "\n",
    "def ceil_by_factor(number: int, factor: int) -> int:\n",
    "    return math.ceil(number / factor) * factor\n",
    "\n",
    "def floor_by_factor(number: int, factor: int) -> int:\n",
    "    return math.floor(number / factor) * factor\n",
    "\n",
    "def smart_resize(\n",
    "    height: int, width: int, factor: int = IMAGE_FACTOR, min_pixels: int = MIN_PIXELS, max_pixels: int = MAX_PIXELS\n",
    ") -> tuple[int, int]:\n",
    "    if min(height, width) == 0: return 0, 0\n",
    "    if max(height, width) / min(height, width) > MAX_RATIO:\n",
    "        print(f\"Warning: Image with extreme aspect ratio {width}x{height} skipped.\")\n",
    "        return 0, 0\n",
    "    h_bar = max(factor, round_by_factor(height, factor))\n",
    "    w_bar = max(factor, round_by_factor(width, factor))\n",
    "    if h_bar * w_bar > max_pixels:\n",
    "        beta = math.sqrt((height * width) / max_pixels)\n",
    "        h_bar = max(factor, floor_by_factor(height / beta, factor))\n",
    "        w_bar = max(factor, floor_by_factor(width / beta, factor))\n",
    "    elif h_bar * w_bar < min_pixels:\n",
    "        beta = math.sqrt(min_pixels / (height * width))\n",
    "        h_bar = ceil_by_factor(height * beta, factor)\n",
    "        w_bar = ceil_by_factor(width * beta, factor)\n",
    "    return h_bar, w_bar\n",
    "\n",
    "\n",
    "def parse_and_validate_boxes(s):\n",
    "    valid_box_regex = r'\\{<(-?\\d+(?:\\.\\d+)?)><(-?\\d+(?:\\.\\d+)?)><(-?\\d+(?:\\.\\d+)?)><(-?\\d+(?:\\.\\d+)?)>\\}'\n",
    "    parsed_boxes = []\n",
    "    for box_coords in re.findall(valid_box_regex, s):\n",
    "        box = list(map(float, box_coords))\n",
    "        if box[0] < box[2] and box[1] < box[3]:\n",
    "            parsed_boxes.append(box)\n",
    "    return parsed_boxes\n",
    "\n",
    "def first_existing_image(rel_path: str, prefixes=(\"\", \"ARTA_LEGO\", \"ARTA_LEGO/ARTA_LEGO\")):\n",
    "    for pfx in prefixes:\n",
    "        p = Path(pfx) / rel_path\n",
    "        if p.is_file():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No image found for {rel_path} in {prefixes}\")\n",
    "\n",
    "def match_and_debug(gt, pr):\n",
    "    M, N = len(gt), len(pr)\n",
    "    if M == 0 or N == 0: return [], 0.0\n",
    "\n",
    "    cost_matrix = np.ones((M, N))\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            g, p = gt[i], pr[j]\n",
    "            inter_x1, inter_y1 = max(g[0], p[0]), max(g[1], p[1])\n",
    "            inter_x2, inter_y2 = min(g[2], p[2]), min(g[3], p[3])\n",
    "            inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "            g_area = (g[2] - g[0]) * (g[3] - g[1])\n",
    "            p_area = (p[2] - p[0]) * (p[3] - p[1])\n",
    "            union_area = g_area + p_area - inter_area\n",
    "            iou = inter_area / union_area if union_area > 0 else 0\n",
    "            cost_matrix[i, j] = 1 - iou\n",
    "\n",
    "    rows, cols = linear_sum_assignment(cost_matrix)\n",
    "    matched = [(r, c, 1 - cost_matrix[r, c]) for r, c in zip(rows, cols)]\n",
    "    return matched, sum(m[2] for m in matched)\n",
    "\n",
    "\n",
    "with open('eval_object_thinking.jsonl') as f:\n",
    "    data = [json.loads(l) for l in f]\n",
    "\n",
    "total_iou, all_count, skipped = 0.0, 0, 0\n",
    "nonzero_iou_examples = []\n",
    "\n",
    "for idx, ex in enumerate(data):\n",
    "    user_img_dict = None\n",
    "    for m in ex[\"messages\"]:\n",
    "        if m[\"role\"] == \"user\":\n",
    "            user_img_dict = next((c for c in m[\"content\"] if c.get(\"type\") == \"image\"), None)\n",
    "            break\n",
    "\n",
    "    if not user_img_dict:           \n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    img_rel_path = user_img_dict[\"image\"].replace(\"file://\", \"\")\n",
    "    gt_boxes_norm = parse_and_validate_boxes(ex['ground_truth'])\n",
    "    pr_boxes_raw  = parse_and_validate_boxes(ex['prediction'])\n",
    "\n",
    "    try:\n",
    "        with Image.open(first_existing_image(img_rel_path)) as img:\n",
    "            w_orig, h_orig = img.size\n",
    "    except FileNotFoundError:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if \"resized_width\" in user_img_dict and \"resized_height\" in user_img_dict:\n",
    "        w_new = int(user_img_dict[\"resized_width\"])\n",
    "        h_new = int(user_img_dict[\"resized_height\"])\n",
    "    else:                               \n",
    "        h_new, w_new = smart_resize(h_orig, w_orig)\n",
    "\n",
    "    if any(v == 0 for v in (w_orig, h_orig, w_new, h_new)):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if (all(0.0 <= c <= 100.0 for b in pr_boxes_raw for c in b) and\n",
    "        all(0.0 <= c <= 100.0 for b in gt_boxes_norm for c in b)):\n",
    "        matched, sum_iou = match_and_debug(gt_boxes_norm, pr_boxes_raw)\n",
    "    \n",
    "    else:\n",
    "        gt_boxes_px = [[\n",
    "            b[0] / 100 * w_orig, b[1] / 100 * h_orig,\n",
    "            b[2] / 100 * w_orig, b[3] / 100 * h_orig,\n",
    "        ] for b in gt_boxes_norm]\n",
    "\n",
    "        pr_boxes_px = []\n",
    "        for b in pr_boxes_raw:\n",
    "            if any(c > 100.0 for c in b):            # already pixels (resized)\n",
    "                x1, y1, x2, y2 = b\n",
    "                pr_boxes_px.append([\n",
    "                    x1 / w_new * w_orig, y1 / h_new * h_orig,\n",
    "                    x2 / w_new * w_orig, y2 / h_new * h_orig,\n",
    "                ])\n",
    "            else:                                     # 0‑100 of resized image\n",
    "                pr_boxes_px.append([\n",
    "                    b[0] / 100 * w_orig, b[1] / 100 * h_orig,\n",
    "                    b[2] / 100 * w_orig, b[3] / 100 * h_orig,\n",
    "                ])\n",
    "\n",
    "        matched, sum_iou = match_and_debug(gt_boxes_px, pr_boxes_px)\n",
    "\n",
    "    all_count += 1\n",
    "    if matched:\n",
    "        # Compute mean IoU for this example\n",
    "        mean_iou = sum_iou / len(matched) if len(matched) > 0 else 0.0\n",
    "        total_iou += mean_iou\n",
    "        if mean_iou > 0.0:\n",
    "            nonzero_iou_examples.append(mean_iou)\n",
    "    else:\n",
    "        # Add 0.0 for invalid examples\n",
    "        total_iou += 0.0\n",
    "\n",
    "# Plotting\n",
    "sns.set_style(\"whitegrid\") \n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "print(f\"\\nProcessed {all_count} examples (skipped {skipped}).\")\n",
    "\n",
    "if all_count > 0:\n",
    "    mean_all = total_iou / all_count\n",
    "    print(f\"Overall Mean IoU (all examples)        : {mean_all:.4f}\")\n",
    "\n",
    "    if nonzero_iou_examples:\n",
    "        mean_nozeros = np.mean(nonzero_iou_examples)\n",
    "        print(f\"Overall Mean IoU (non-zero examples) : {mean_nozeros:.4f}\")\n",
    "    else:\n",
    "        print(\"No examples with IoU > 0\")\n",
    "\n",
    "    # Histogram of IoU values\n",
    "    iou_values = [0.0] * (all_count - len(nonzero_iou_examples)) + nonzero_iou_examples\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(iou_values, bins=20, color=\"#FF9F43\", alpha=0.8, edgecolor=\"black\")\n",
    "    plt.xlabel('IoU Values', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.title('Distribution of IoU', fontsize=16, pad=20)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.axvline(np.mean(iou_values), color='red', linestyle='--', linewidth=2, label=f'Mean IoU: {np.mean(iou_values):.4f}')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No examples were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Visualise N worst & N best with detailed metrics including demos =====\n",
    "import json, re, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "\n",
    "N = 10  # Show top N and bottom N examples\n",
    "\n",
    "box_re = re.compile(r'\\{<(-?\\d+(?:\\.\\d+)?)><(-?\\d+(?:\\.\\d+)?)>'\n",
    "                    r'<(-?\\d+(?:\\.\\d+)?)><(-?\\d+(?:\\.\\d+)?)>\\}')\n",
    "\n",
    "def boxes(txt):                 # extract every {<x1><y1><x2><y2>}\n",
    "    return [list(map(float, b)) for b in box_re.findall(txt)]\n",
    "\n",
    "def last_user_img(msgs):\n",
    "    for m in reversed(msgs):\n",
    "        if m[\"role\"] == \"user\":\n",
    "            for c in m[\"content\"]:\n",
    "                if c[\"type\"] == \"image\":\n",
    "                    return c[\"image\"].lstrip(\"file://\")\n",
    "    return None\n",
    "\n",
    "def get_demo_message(messages):\n",
    "    \"\"\"Returns the first system or assistant message with a user+assistant pair\"\"\"\n",
    "    demo = {\"user\": \"\", \"assistant\": \"\"}\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"system\" and isinstance(m[\"content\"], list):\n",
    "            for c in m[\"content\"]:\n",
    "                if c[\"type\"] == \"image\":\n",
    "                    img_path = c[\"image\"].lstrip(\"file://\")\n",
    "                    return {\"demo_image\": img_path}\n",
    "        elif m[\"role\"] == \"user\" and isinstance(m[\"content\"], list):\n",
    "            for c in m[\"content\"]:\n",
    "                if c[\"type\"] == \"image\":\n",
    "                    img_path = c[\"image\"].lstrip(\"file://\")\n",
    "                    txt = next((ct[\"text\"] for ct in m[\"content\"] if ct[\"type\"] == \"text\"), \"\")\n",
    "                    demo[\"user\"] = txt\n",
    "                    return {\"demo_image\": img_path, \"demo_prompt\": txt}\n",
    "    return {}\n",
    "\n",
    "def first_path(rel, roots=(\"\", \"ARTA_LEGO\", \"ARTA_LEGO/ARTA_LEGO\")):\n",
    "    for r in roots:\n",
    "        p = Path(r) / rel\n",
    "        if p.is_file():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def mean_iou(gt, pr):                                   # Hungarian + mean IoU\n",
    "    M, N = len(gt), len(pr)\n",
    "    if M == 0 or N == 0:\n",
    "        return 0.0\n",
    "    cost = np.zeros((M, N))\n",
    "    for i, g in enumerate(gt):\n",
    "        for j, p in enumerate(pr):\n",
    "            ix = max(0, min(g[2], p[2]) - max(g[0], p[0]))\n",
    "            iy = max(0, min(g[3], p[3]) - max(g[1], p[1]))\n",
    "            inter = ix * iy\n",
    "            ua = (g[2] - g[0]) * (g[3] - g[1])\n",
    "            ub = (p[2] - p[0]) * (p[3] - p[1])\n",
    "            union = ua + ub - inter\n",
    "            cost[i, j] = 1 - inter / union if union else 1\n",
    "    r, c = linear_sum_assignment(cost)\n",
    "    return float(np.mean([1 - cost[ri, ci] for ri, ci in zip(r, c)]))\n",
    "\n",
    "def ensure_pct(pred, w, h):\n",
    "    \"\"\"Return (all‑percent‑boxes, all‑pixel‑boxes).\"\"\"\n",
    "    pct, px = [], []\n",
    "    for x1, y1, x2, y2 in pred:\n",
    "        if 0 <= x1 <= 100 and 0 <= y1 <= 100 and 0 <= x2 <= 100 and 0 <= y2 <= 100:\n",
    "            pct.append([x1, y1, x2, y2])\n",
    "            px.append([x1 / 100 * w, y1 / 100 * h, x2 / 100 * w, y2 / 100 * h])\n",
    "        else:                                              # pixel → percent\n",
    "            pct.append([x1 / w * 100, y1 / h * 100, x2 / w * 100, y2 / h * 100])\n",
    "            px.append([x1, y1, x2, y2])\n",
    "    return pct, px\n",
    "\n",
    "def get_last_turn(messages):\n",
    "    user_text = \"\"\n",
    "    assistant_text = \"\"\n",
    "    for m in reversed(messages):\n",
    "        if m[\"role\"] == \"assistant\" and not assistant_text:\n",
    "            assistant_text = m[\"content\"]\n",
    "        elif m[\"role\"] == \"user\" and not user_text:\n",
    "            for c in m[\"content\"]:\n",
    "                if c[\"type\"] == \"text\":\n",
    "                    user_text = c[\"text\"]\n",
    "    return {\"user\": user_text, \"assistant\": assistant_text}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "ex_list = []\n",
    "\n",
    "with open(\"eval_object_thinking.jsonl\", encoding=\"utf-8\") as fh:\n",
    "    for rec in map(json.loads, fh):\n",
    "        img_rel = last_user_img(rec[\"messages\"])\n",
    "        if not img_rel:\n",
    "            continue\n",
    "        path = first_path(img_rel)\n",
    "        if not path:\n",
    "            continue\n",
    "        gt_raw = boxes(rec[\"ground_truth\"])\n",
    "        pr_raw = boxes(rec[\"prediction\"])\n",
    "        if not (gt_raw and pr_raw):\n",
    "            continue\n",
    "\n",
    "        w, h = Image.open(path).size\n",
    "        gt_pct = gt_raw  # GT already in percent\n",
    "        pr_pct, pr_px = ensure_pct(pr_raw, w, h)\n",
    "\n",
    "        iou_score = mean_iou(gt_pct, pr_pct)\n",
    "        last_turn = get_last_turn(rec[\"messages\"])\n",
    "        demo_info = get_demo_message(rec[\"messages\"])\n",
    "\n",
    "        ex_list.append({\n",
    "            \"iou\": iou_score,\n",
    "            \"path\": path,\n",
    "            \"gt_raw\": gt_raw,\n",
    "            \"pr_raw\": pr_raw,\n",
    "            \"pr_px\": pr_px,\n",
    "            \"pr_pct\": pr_pct,\n",
    "            \"gt_pct\": gt_pct,\n",
    "            \"width\": w,\n",
    "            \"height\": h,\n",
    "            \"last_turn\": last_turn,\n",
    "            \"demo\": demo_info,\n",
    "            \"ground_truth\": rec[\"ground_truth\"],\n",
    "            \"prediction\": rec[\"prediction\"]\n",
    "        })\n",
    "\n",
    "all_scores = [e[\"iou\"] for e in ex_list]\n",
    "print(f\"Mean IoU over {len(all_scores)} examples: {np.mean(all_scores):.4f}\")\n",
    "\n",
    "# Legend patches\n",
    "gt_patch = mpatches.Patch(color='lime', label='Ground Truth')\n",
    "pr_patch = mpatches.Patch(color='red', label='Prediction')\n",
    "\n",
    "# Load font\n",
    "\n",
    "base_font = ImageFont.truetype(\"arial.ttf\", size=200)\n",
    "\n",
    "\n",
    "# Sort by IoU\n",
    "ex_list.sort(key=lambda x: x[\"iou\"])\n",
    "worst_examples = ex_list[:N]\n",
    "best_examples = ex_list[-N:]\n",
    "\n",
    "# Function to draw image with boxes\n",
    "def draw_boxes_and_print_info(example, rank_title):\n",
    "    path = example[\"path\"]\n",
    "    w, h = example[\"width\"], example[\"height\"]\n",
    "    img = Image.open(path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "\n",
    "    try:\n",
    "        font_size = int(h * 0.05)\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=font_size)\n",
    "    except IOError:\n",
    "        font = base_font\n",
    "\n",
    "    # Draw aspect ratio banner\n",
    "    common_divisor = math.gcd(w, h)\n",
    "    ar_w = w // common_divisor\n",
    "    ar_h = h // common_divisor\n",
    "    text = f\"{ar_w}:{ar_h}\"\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    pad = 4\n",
    "    bg = (0, 0, 0, 160)\n",
    "    draw.rectangle((2, 2, bbox[2] + 2 * pad, bbox[3] + 2 * pad), fill=bg)\n",
    "    draw.text((2 + pad, 2 + pad), text, fill=\"yellow\", font=font)\n",
    "\n",
    "    # Draw ground truth boxes\n",
    "    for x1, y1, x2, y2 in example[\"gt_raw\"]:\n",
    "        draw.rectangle([x1 / 100 * w, y1 / 100 * h, x2 / 100 * w, y2 / 100 * h],\n",
    "                      outline=\"lime\", width=3)\n",
    "\n",
    "    # Draw prediction boxes\n",
    "    for x1, y1, x2, y2 in example[\"pr_raw\"]:\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            draw.rectangle([x1 / 100 * w, y1 / 100 * h, x2 / 100 * w, y2 / 100 * h],\n",
    "                          outline=\"red\", width=3)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(1, 2 if \"demo_image\" in example[\"demo\"] else 1, figsize=(12, 6))\n",
    "    if \"demo_image\" in example[\"demo\"]:\n",
    "        demo_path = first_path(example[\"demo\"][\"demo_image\"])\n",
    "        if demo_path:\n",
    "            demo_img = Image.open(demo_path).convert(\"RGBA\")\n",
    "            ax[0].imshow(demo_img)\n",
    "            ax[0].axis(\"off\")\n",
    "            ax[0].set_title(\"Demo Example\", fontsize=12)\n",
    "\n",
    "            # Print demo info\n",
    "            print(\"\\nDEMO EXAMPLE:\")\n",
    "            print(\"-\"*60)\n",
    "            print(f\"IMAGE PATH: {demo_path}\")\n",
    "            print(f\"PROMPT: {example['demo']['demo_prompt']}\")\n",
    "            print(\"-\"*60)\n",
    "        else:\n",
    "            ax[0].text(0.5, 0.5, \"No Demo Available\", ha=\"center\", va=\"center\")\n",
    "        ax[1].imshow(img)\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].set_title(f\"{rank_title} | Mean IoU = {example['iou']:.3f}\", fontsize=12)\n",
    "    else:\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"{rank_title} | Mean IoU = {example['iou']:.3f}\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print additional info\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "    print(f\"IMAGE PATH: {path}\")\n",
    "    print(f\"SIZE: {w}x{h} | ASPECT RATIO: {ar_w}:{ar_h}\")\n",
    "    print(f\"GROUND TRUTH ({len(example['gt_raw'])} boxes):\")\n",
    "    for i, box in enumerate(example[\"gt_raw\"]):\n",
    "        print(f\"  GT Box {i+1}: {box}\")\n",
    "    print(f\"PREDICTION ({len(example['pr_raw'])} boxes):\")\n",
    "    for i, box in enumerate(example[\"pr_raw\"]):\n",
    "        print(f\"  PR Box {i+1}: {box} | Pixel: {example['pr_px'][i]}\")\n",
    "    print(\"\\nUSER PROMPT:\")\n",
    "    print(example[\"last_turn\"][\"user\"])\n",
    "    print(\"\\nASSISTANT RESPONSE:\")\n",
    "    print(example[\"last_turn\"][\"assistant\"])\n",
    "    print(\"\\nRAW GROUND TRUTH STRING:\")\n",
    "    print(example[\"ground_truth\"])\n",
    "    print(\"\\nRAW PREDICTION STRING:\")\n",
    "    print(example[\"last_turn\"][\"assistant\"])\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "# Display best and worst\n",
    "print(\"\\n\\n=== BEST EXAMPLES ===\")\n",
    "for idx, ex in enumerate(best_examples, 1):\n",
    "    draw_boxes_and_print_info(ex, f\"Best #{idx}\")\n",
    "\n",
    "print(\"\\n\\n=== WORST EXAMPLES ===\")\n",
    "for idx, ex in enumerate(worst_examples, 1):\n",
    "    draw_boxes_and_print_info(ex, f\"Worst #{idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
